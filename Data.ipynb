{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file = 'dev_sent_emo.csv'\n",
    "test_file = 'test_sent_emo.csv'\n",
    "train_file = 'train_sent_emo.csv'\n",
    "\n",
    "dev_data = pd.read_csv(dev_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "train_data = pd.read_csv(train_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:16,059</td>\n",
       "      <td>00:16:21,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:21,940</td>\n",
       "      <td>00:16:23,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:23,442</td>\n",
       "      <td>00:16:26,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:26,820</td>\n",
       "      <td>00:16:29,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance          Speaker  \\\n",
       "0       1  also I was the point person on my companys tr...         Chandler   \n",
       "1       2                   You mustve had your hands full.  The Interviewer   \n",
       "2       3                            That I did. That I did.         Chandler   \n",
       "3       4      So lets talk a little bit about your duties.  The Interviewer   \n",
       "4       5                             My duties?  All right.         Chandler   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   neutral   neutral            0             0       8       21   \n",
       "1   neutral   neutral            0             1       8       21   \n",
       "2   neutral   neutral            0             2       8       21   \n",
       "3   neutral   neutral            0             3       8       21   \n",
       "4  surprise  positive            0             4       8       21   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:16:16,059  00:16:21,731  \n",
       "1  00:16:21,940  00:16:23,442  \n",
       "2  00:16:23,442  00:16:26,389  \n",
       "3  00:16:26,820  00:16:29,572  \n",
       "4  00:16:34,452  00:16:40,917  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file = 'dev_sent_emo.csv'\n",
    "test_file = 'test_sent_emo.csv'\n",
    "train_file = 'train_sent_emo.csv'\n",
    "\n",
    "dev_data = pd.read_csv(dev_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "train_data = pd.read_csv(train_file)\n",
    "\n",
    "dev_data = dev_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "dev_data['Utterance'] = dev_data['Utterance'].str.strip()\n",
    "test_data['Utterance'] = test_data['Utterance'].str.strip()\n",
    "train_data['Utterance'] = train_data['Utterance'].str.strip()\n",
    "\n",
    "dev_data['Utterance'] = dev_data['Utterance'].str.lower()\n",
    "test_data['Utterance'] = test_data['Utterance'].str.lower()\n",
    "train_data['Utterance'] = train_data['Utterance'].str.lower()\n",
    "\n",
    "le = LabelEncoder()\n",
    "dev_data['Emotion'] = le.fit_transform(dev_data['Emotion'])\n",
    "test_data['Emotion'] = le.fit_transform(test_data['Emotion'])\n",
    "train_data['Emotion'] = le.fit_transform(train_data['Emotion'])\n",
    "\n",
    "dev_data.to_csv('dev_sent_emo_preprocessed.csv', index=False)\n",
    "test_data.to_csv('test_sent_emo_preprocessed.csv', index=False)\n",
    "train_data.to_csv('train_sent_emo_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file = 'dev_sent_emo_preprocessed.csv'\n",
    "test_file = 'test_sent_emo.csv'\n",
    "train_file = 'train_sent_emo.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv(dev_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "train_data = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>oh my god, hes lost it. hes totally lost it.</td>\n",
       "      <td>Phoebe</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:20:57,256</td>\n",
       "      <td>00:21:00,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what?</td>\n",
       "      <td>Monica</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>00:21:01,927</td>\n",
       "      <td>00:21:03,261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>or! or, we could go to the bank, close our acc...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:24,660</td>\n",
       "      <td>00:12:30,915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>youre a genius!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:32,334</td>\n",
       "      <td>00:12:33,960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>aww, man, now we wont be bank buddies!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:12:34,211</td>\n",
       "      <td>00:12:37,505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance   Speaker  \\\n",
       "0       1     oh my god, hes lost it. hes totally lost it.    Phoebe   \n",
       "1       2                                              what?    Monica   \n",
       "2       3  or! or, we could go to the bank, close our acc...      Ross   \n",
       "3       4                                   youre a genius!  Chandler   \n",
       "4       5            aww, man, now we wont be bank buddies!      Joey   \n",
       "\n",
       "   Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0        5  negative            0             0       4        7   \n",
       "1        6  negative            0             1       4        7   \n",
       "2        4   neutral            1             0       4        4   \n",
       "3        3  positive            1             1       4        4   \n",
       "4        5  negative            1             2       4        4   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:20:57,256  00:21:00,049  \n",
       "1  00:21:01,927  00:21:03,261  \n",
       "2  00:12:24,660  00:12:30,915  \n",
       "3  00:12:32,334  00:12:33,960  \n",
       "4  00:12:34,211  00:12:37,505  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data[\"Utterance\"] = dev_data[\"Utterance\"].str.replace(\"\\x92\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you love i'd\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "test = \"i'd love you\"\n",
    "words = test.split()\n",
    "random.shuffle(words)\n",
    "result = ' '.join(words)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def shuffleUtterance(data):\n",
    "    shuffled = []\n",
    "    for row in data:\n",
    "        words = row.split()\n",
    "        random.shuffle(words)\n",
    "        result = ' '.join(words)\n",
    "        shuffled.append(result)\n",
    "    return shuffled\n",
    "# if number > word's size then all words are shuffled\n",
    "def shuffleWord(data, number):\n",
    "    shuffled_row= []\n",
    "    for row in data:\n",
    "        words = row.split()\n",
    "        number = min(number, len(words))\n",
    "        selected = random.sample(words,number)\n",
    "        result = []\n",
    "        for word in words:\n",
    "            if word in selected:\n",
    "                result.append(shuffleLetter(word))\n",
    "            else:\n",
    "                result.append(word)\n",
    "        shuffled_sentence = ' '.join(result)\n",
    "        shuffled_row.append(shuffled_sentence)\n",
    "    return shuffled_row\n",
    "\n",
    "\n",
    "\n",
    "def shuffleLetter(word):\n",
    "    w_list = list(word)\n",
    "    random.shuffle(w_list)\n",
    "    result = ''.join(w_list)\n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aoleicao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/aoleicao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aoleicao/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.set_proxy(\"http_proxy=http://127.0.0.1:1087\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet \n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return synonyms\n",
    "def synonyms_replacement(data, number):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        words = row.split()\n",
    "        number = min(number, len(words))\n",
    "        selected = random.sample(words,number)\n",
    "        replaced = []\n",
    "        for word in words:\n",
    "            if word in selected:\n",
    "                syn = get_synonyms(word)\n",
    "                if syn:\n",
    "                    word = random.choice(syn)\n",
    "                    replaced.append(word)\n",
    "                else:\n",
    "                    replaced.append(word)\n",
    "            else:\n",
    "                replaced.append(word)   \n",
    "        replaced_sentence = ' '.join(replaced)\n",
    "        result.append(replaced_sentence)\n",
    "    return result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'),\n",
       " ('love', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('but', 'CC'),\n",
       " ('everything', 'NN'),\n",
       " ('changed', 'VBD')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "example = \"i love you but everything changed\"\n",
    "\n",
    "nltk.pos_tag(example.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
